##------------------------------------------------------------------------##
#  Required files to run this code
#'outcome/api.covid19india.org_24th_Mar_2021.csv'
#'1. beds and ventilators/hospital_capacity.csv'
#'2. national health profile 2019/national_health_profile_state.csv'
#'3. census 2011/data_state.csv'
#'3. census 2011/data_dist.csv'
##------------------------------------------------------------------------##

#Load packages
library(rvest)     
library(tidyverse)
library(janitor)

##------------------------------------------------------------------------##
#  Load and make list of URL's 
#The list is saved in 'outcome/api.covid19india.org_24th_Mar_2021.csv'
#However, since 'Raw Data' is updated periodically,
#links for 'Raw Data' will be generated by the following code.
##------------------------------------------------------------------------##

#Load list of URL's 
setwd("C:/Users/samsung/Desktop/BIOS/Research_Covid/git/Research_COVID")
links <- read.csv("outcome/api.covid19india.org_24th_Mar_2021.csv")
  ##`links` have information on datasets except raw_data. We need to make `links_rawdata`.

#Make list of URL links for 'Raw Data'
page <- read_html("https://api.covid19india.org")
page_p <- page %>% html_nodes("table") %>%  html_text() #save html text in the node "table" into `page_p`
page_p <- page_p[1] #save only the 4th string.
page_split <- str_split(page_p, " | ")[[1]] #split the string by a pattern " | "
index <- page_split %>% str_detect("csv$") #find urls using that urls ends with ".csv"
raw_data_links <- page_split[index]
#raw_data_links <- raw_data_links %>% str_remove("\n")

links_rawdata <- data.frame(str_match(raw_data_links, "https://api.covid19india.org/csv/latest/\\s*(.*?)\\s*.csv"))
names(links_rawdata) <- c("Link", "SheetName")
head(links_rawdata)
 ##`links_rawdata` and `links` have the same structure except the column 'Description'


##------------------------------------------------------------------------##
# Download and load files on the list.
##------------------------------------------------------------------------##

#Set location where files will be downloaded
location <- "outcome/downloads"
dir.create(location)

#Download files except raw datasets
for (i in 1:nrow(links)){
  url <- links$Link[i]
  file <- paste0(location, "/",links$SheetName[i], ".csv")
  download.file(url, file, quiet = TRUE, mode = "wb") 
}
#Download raw datasets
for (i in 1:nrow(links_rawdata)){
  url <- links_rawdata$Link[i]
  file <- paste0(location, "/",links_rawdata$SheetName[i], ".csv")
  download.file(url, file, quiet = TRUE, mode = "wb") 
}

#Load the downloaded files except raw datasets
for (i in 1:nrow(links)){
  assign(links$SheetName[i],
         read.csv(paste0(location, "/",links$SheetName[i], ".csv")) %>%
           clean_names() %>% 
           mutate(sheet_name = links$SheetName[i],
                  description = links$Description[i])
  )
}

#Load raw datasets
for (i in 1:nrow(links_rawdata)){
  assign(links_rawdata$SheetName[i],
         read.csv(paste0(location, "/",links_rawdata$SheetName[i], ".csv")) %>%
           clean_names() %>% 
           mutate(sheet_name = links_rawdata$SheetName[i])
  )
}

##------------------------------------------------------------------------##
# Stack `raw_data{}` files. 
# Before stacking, match the columns of raw data files.
##------------------------------------------------------------------------##
names(raw_data1) == names(raw_data2)
names(raw_data2) == names(raw_data3) #will return warning.
names(raw_data3) == names(raw_data24) 
 ##`raw_data1` and `raw_data2` have different columns than others.

raw_data1$entry_id <- NA # make new column
raw_data2$entry_id <- NA # make new column
raw_data1 <- raw_data1[, -c(4, 20)] #remove Estimated Onset Date and Backup Notes
raw_data2 <- raw_data2[, -c(4, 20)] #remove Estimated Onset Date and Backup Notes

names(raw_data1) %in% names(raw_data20) #All True, which means all columns in raw_data1 are in raw_data20 regardless of the order
names(raw_data20) %in% names(raw_data1) #All True, which means all columns in raw_data20 are in raw_data1 regardless of the order

#Match the orders of columns.
reorder_idx <- match(names(raw_data3), names(raw_data1))
raw_data1 <- raw_data1[,reorder_idx]
raw_data2 <- raw_data2[,reorder_idx]

all(names(raw_data2) == names(raw_data3))

#Stack `raw_data{}` files and save it as 'raw_data_combined'
raw_data_combined <- rbind(raw_data1, raw_data2, raw_data3, raw_data4, raw_data5, raw_data6,
                           raw_data7, raw_data8, raw_data9, raw_data10, raw_data11, raw_data12,
                           raw_data13, raw_data14, raw_data15, raw_data16, raw_data17, raw_data18,
                           raw_data19, raw_data20, raw_data21, raw_data22, raw_data23, raw_data24,
                           raw_data25, raw_data26, raw_data27, raw_data28, raw_data29) ### Need to update this code yet -----------------------
names(raw_data_combined) # column names of `raw_data_combined`, but we need only some of them.
  ## select only necessary columns and save them.
raw_data_combined <-
raw_data_combined %>% 
  select(entry_id, patient_number, date_announced, age_bracket, gender, 
         detected_city, detected_district, detected_state,
         state_code, num_cases, current_status, contracted_from_which_patient_suspected, notes)

#Save 'raw_data_combined' in 'outcome' folder.
write.csv(raw_data_combined, "outcome/raw_data_combined.csv")


##------------------------------------------------------------------------##
# Combine relevant variables in a state level, 
# which will be saved in the object 'var_relevant_state'
# For time series variable, median is used.
# Data that will be used:
#   -'outcome/downloads/statewise_tested_numbers_data.csv' : it was downloaded and loaded above.
#   -'outcome/downloads/cowin_vaccine_data_statewise.csv' : it was downloaded and loaded above.
#   -'1. beds and ventilators/hospital_capacity.csv'
#   -'2. national health profile 2019/national_health_profile_state.csv'
##------------------------------------------------------------------------##

#Make 'vrs1' using 'statewise_tested_numbers_datarelevant' 
#The original data is a time series data. Therefore, it is not organized in a state level.
#It will be organized by functions `group_by` and `summarise`.
#For each state, time series values will be summarised by median.
#In the final step, 'vrs1' will be combined into 'var_relevant_state'

vrs1<-
  statewise_tested_numbers_data %>% group_by(state) %>%
  summarise(total_tested=median(total_tested, na.rm = TRUE),
            total_num_icu_beds=median(total_num_icu_beds, na.rm = TRUE),
            total_num_ventilators=median(total_num_ventilators, na.rm = TRUE),
            total_num_of_o2_beds=median(total_num_of_o2_beds, na.rm = TRUE),
            total_num_beds_normal_isolation=median(total_num_beds_normal_isolation, na.rm = TRUE),
            total_ppe=median(total_ppe, na.rm = TRUE),
            total_n95_masks=median(total_n95_masks, na.rm = TRUE),
            covid_enquiry_calls=median(covid_enquiry_calls, na.rm = TRUE),
            number_of_containment_zones=median(number_of_containment_zones, na.rm = TRUE)
            )

#Make 'vrs2' using 'cowin_vaccine_data_statewise'.
#The original data is a time series data. Therefore, it is not organized in a state level.
#It will be organized by functions `group_by` and `summarise`.
#For each state, time series values will be summarised by median.
#In the final step, 'vrs2' will be combined into 'var_relevant_state'

vrs2 <- 
  cowin_vaccine_data_statewise %>% group_by(state) %>%
  summarise(total_covaxin_administered=median(total_covaxin_administered, na.rm=TRUE),
            total_covi_shield_administered=median(total_covi_shield_administered, na.rm=TRUE),
            total_doses_administered=median(total_doses_administered, na.rm=TRUE)
            )

#Load '1. beds and ventilators/hospital_capacity.csv' as 'vrs3'
#In the final step, 'vrs3' will be combined into 'var_relevant_state' as well.
vrs3 <- #hospital capicity variables in state level.
  read_csv("1. beds and ventilators/hospital_capacity.csv")


#check non-intersecting states between vrs's
all(vrs1$state %in% vrs2$state) #All states in vrs1 are listed in vrs2 ? TRUE
all(vrs1$state %in% vrs3$state) #All states in vrs1 are listed in vrs3 ? TRUE
all(vrs2$state %in% vrs1$state) #All states in vrs2 are listed in vrs1 ? FALSE
all(vrs3$state %in% vrs1$state) #All states in vrs3 are listed in vrs1 ? FALSE

#For the FALSE, check which states are non-intersecting.
vrs2$state[!(vrs2$state %in% vrs1$state)]
vrs3$state[!(vrs3$state %in% vrs1$state)] #see hospital_capacity.csv in README.txt

#Combine vrs1, vrs2, and vrs3 and save the combined data set as `var_relevant_state`
var_relevant_state <- inner_join(vrs1, vrs2, by="state") #Combine 'vrs1' and 'vrs2'
var_relevant_state <- inner_join(var_relevant_state, vrs3, by="state") #Combine 'var_relevant_state' and 'vrs3'
View(var_relevant_state)

#'1. beds and ventilators/hospital_capacity.csv' (vrs3) has an 'Assumption' row.
#Add it at the last row of 'var_relevant_state'
m <- match(names(var_relevant_state), names(vrs3))
t(tail(vrs3,1))[m]
var_relevant_state <- rbind(var_relevant_state, t(tail(vrs3,1))[m])


#05/12/2021. 
#Load '2. national health profile 2019/national_health_profile_state.csv' as 'vrs4'
#Combine it into 'var_relevant_state'
vrs4 <- #national_health_profile_state
  read_csv("2. national health profile 2019/national_health_profile_state.csv")

#check non-intersecting states between 'var_relevant_state' and 'vrs4'.
all(var_relevant_state$state %in% vrs4$state) #All states in 'var_relevant_state' are listed in 'vrs4' ? FALSE
all(vrs4$state %in% var_relevant_state$state) #All states in 'vrs4' are listed in 'var_relevant_state' ? FALSE

#See which states are non-intersecting.
var_relevant_state$state[!(var_relevant_state$state %in% vrs4$state)]
vrs4$state[!(vrs4$state %in% var_relevant_state$state)] #see national_health_profile_state.csv in README.txt

#update 'var_relevant_state.'.
var_relevant_state <- left_join(var_relevant_state, vrs4, by="state")



#06/01/2021. 
#Load '3. census 2011/data_state.csv' as 'vrs5'
#Combine it into 'var_relevant_state'
vrs5 <- read_csv("3. census 2011/data_state.csv")

#remove the first column
vrs5 <- vrs5[, -1]

#See unmatched state names. Since Ladakh and Telangana was established later than 2011,
#they are not listed in the Census 2011 data.
var_relevant_state$state[!(var_relevant_state$state %in% vrs5$state_name)]

#Before combine the two data set(var_relevant_state and vrs5), change the variable names of census 2011 data.
names(vrs5)
paste0("c11_", names(vrs5)) #Those will be the new variable names.
names(vrs5) <- paste0("c11_", names(vrs5))
names(vrs5)

#Remove unnecessarry variables.
vrs5 <- vrs5 %>% select(-c11_state_code, -c11_dist_code, -c11_Area, -c11_Age) 

#Join the two dataset.
var_relevant_state <- left_join(var_relevant_state, vrs5, by=c("state"= "c11_state_name"))
View(var_relevant_state)

#Save the final output in 'outcome' directory.
write.csv(var_relevant_state, "outcome/var_relevant_state.csv")

#-------------------------------------------#
#   Generate 'var_relevant_dist'
#-------------------------------------------#
#Until now, there was no variable by district. However, we got some from the Census 2011.
#Make the dataset from it the first standard data containing variables by district.

#Load "3. census 2011/data_dist.csv" and name it as var_relevant_dist.
var_relevant_dist <- read_csv("3. census 2011/data_dist.csv")
#The key variable of var_relevant_dist is 'dist_name'.
#Again, since Ladakh and Telangana was established later than 2011,
#they are not listed in the Census 2011 data. 
#Therefore, we may need to add districts of them later.

#Remove the first column.
var_relevant_dist <- var_relevant_dist[, -1]

#Change the variable names.
names(var_relevant_dist)
paste0("c11_", names(var_relevant_dist)) #Those will be the new variable names.
names(var_relevant_dist) <- paste0("c11_", names(var_relevant_dist))
names(var_relevant_dist)

#Remove unnecessarry variables.
var_relevant_dist <- var_relevant_dist %>% select(-c11_state_code, -c11_dist_code, -c11_Area, -c11_Age) 



#Save var_relevant_dist in 'outcome' directory.
write.csv(var_relevant_dist, "outcome/var_relevant_dist.csv")
